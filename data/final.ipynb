{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bfb8f17e",
   "metadata": {},
   "source": [
    "## üß™ Data Preparation and Model Setup\n",
    "\n",
    "In this section, we import the necessary libraries for:\n",
    "\n",
    "- Data manipulation\n",
    "- Preprocessing and dimensionality reduction\n",
    "- Handling imbalanced datasets\n",
    "- Building and training a PyTorch model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68ea50b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.1.3 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"c:\\Users\\Bilal\\anaconda3\\envs\\DM_env\\Lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"c:\\Users\\Bilal\\anaconda3\\envs\\DM_env\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"c:\\Users\\Bilal\\anaconda3\\envs\\DM_env\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"c:\\Users\\Bilal\\anaconda3\\envs\\DM_env\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"c:\\Users\\Bilal\\anaconda3\\envs\\DM_env\\Lib\\asyncio\\base_events.py\", line 608, in run_forever\n",
      "    self._run_once()\n",
      "  File \"c:\\Users\\Bilal\\anaconda3\\envs\\DM_env\\Lib\\asyncio\\base_events.py\", line 1936, in _run_once\n",
      "    handle._run()\n",
      "  File \"c:\\Users\\Bilal\\anaconda3\\envs\\DM_env\\Lib\\asyncio\\events.py\", line 84, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"c:\\Users\\Bilal\\anaconda3\\envs\\DM_env\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"c:\\Users\\Bilal\\anaconda3\\envs\\DM_env\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"c:\\Users\\Bilal\\anaconda3\\envs\\DM_env\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"c:\\Users\\Bilal\\anaconda3\\envs\\DM_env\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"c:\\Users\\Bilal\\anaconda3\\envs\\DM_env\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"c:\\Users\\Bilal\\anaconda3\\envs\\DM_env\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"c:\\Users\\Bilal\\anaconda3\\envs\\DM_env\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"c:\\Users\\Bilal\\anaconda3\\envs\\DM_env\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"c:\\Users\\Bilal\\anaconda3\\envs\\DM_env\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"c:\\Users\\Bilal\\anaconda3\\envs\\DM_env\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"c:\\Users\\Bilal\\anaconda3\\envs\\DM_env\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"c:\\Users\\Bilal\\anaconda3\\envs\\DM_env\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"c:\\Users\\Bilal\\anaconda3\\envs\\DM_env\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\Bilal\\AppData\\Local\\Temp\\ipykernel_7976\\999764281.py\", line 16, in <module>\n",
      "    import torch\n",
      "  File \"c:\\Users\\Bilal\\anaconda3\\envs\\DM_env\\Lib\\site-packages\\torch\\__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"c:\\Users\\Bilal\\anaconda3\\envs\\DM_env\\Lib\\site-packages\\torch\\functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"c:\\Users\\Bilal\\anaconda3\\envs\\DM_env\\Lib\\site-packages\\torch\\nn\\__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"c:\\Users\\Bilal\\anaconda3\\envs\\DM_env\\Lib\\site-packages\\torch\\nn\\modules\\__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"c:\\Users\\Bilal\\anaconda3\\envs\\DM_env\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "c:\\Users\\Bilal\\anaconda3\\envs\\DM_env\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at ..\\torch\\csrc\\utils\\tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n"
     ]
    }
   ],
   "source": [
    "# üì¶ Importing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# ‚öôÔ∏è Scikit-learn utilities\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# ‚öñÔ∏è Handling class imbalance\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# üî• PyTorch modules\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "815756f9",
   "metadata": {},
   "source": [
    "## üîß Load and Preprocess Data\n",
    "\n",
    "In this step, we:\n",
    "\n",
    "- Load the dataset from a CSV file\n",
    "- Separate the features `X` and target variable `y`\n",
    "- Encode the target labels if they are categorical\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6a03817",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîß Load and preprocess data\n",
    "df = pd.read_csv(\"Sleep Train 5000.csv\")\n",
    "\n",
    "# üìä Features and target\n",
    "X = df.drop(columns=[df.columns[0]])  # Drop first column (assumed to be the target)\n",
    "y = df[df.columns[0]]                 # Target variable\n",
    "\n",
    "# üî† Encode labels if they are categorical\n",
    "if y.dtype == 'object':\n",
    "    y = LabelEncoder().fit_transform(y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5749fe27",
   "metadata": {},
   "source": [
    "## ‚öñÔ∏è Handle Class Imbalance with SMOTE\n",
    "\n",
    "To address potential class imbalance in the dataset, we use **SMOTE (Synthetic Minority Over-sampling Technique)**.  \n",
    "This generates synthetic samples for the minority class to balance the dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a3d1120",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply SMOTE for balancing\n",
    "X_res, y_res = SMOTE().fit_resample(X, y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "097eebee",
   "metadata": {},
   "source": [
    "## üìè Feature Scaling\n",
    "\n",
    "We scale the features using **StandardScaler** to ensure all features contribute equally to the model.  \n",
    "This transforms the data to have zero mean and unit variance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd6cf9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale and reduce features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_res)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b731cd",
   "metadata": {},
   "source": [
    "## üìâ Dimensionality Reduction with PCA\n",
    "\n",
    "To reduce computational complexity and remove noise, we apply **Principal Component Analysis (PCA)**.  \n",
    "We keep enough components to preserve **95% of the variance** in the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd021bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce dimensionality\n",
    "pca = PCA(n_components=0.95)  # preserve 95% variance\n",
    "X_pca = pca.fit_transform(X_scaled)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f1812f",
   "metadata": {},
   "source": [
    "## üö¶ Split Dataset into Training and Test Sets\n",
    "\n",
    "We split the dataset into:\n",
    "\n",
    "- **Training set** (80%)\n",
    "- **Test set** (20%)\n",
    "\n",
    "to evaluate model performance on unseen data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "415bb81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_pca, y_res, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b04f69",
   "metadata": {},
   "source": [
    "## üî• Convert Data to PyTorch Tensors and Prepare DataLoader\n",
    "\n",
    "- Convert NumPy arrays to PyTorch tensors for model training.\n",
    "- Create a `TensorDataset` and a `DataLoader` for efficient batching and shuffling during training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ba37053",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Torch tensors\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train.to_numpy(), dtype=torch.long)\n",
    "y_test_tensor = torch.tensor(y_test.to_numpy(), dtype=torch.long)\n",
    "\n",
    "train_ds = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_dl = DataLoader(train_ds, batch_size=64, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d0fdfa",
   "metadata": {},
   "source": [
    "## ‚úÖ Improved MLP Model with GELU Activation and Xavier Weight Initialization\n",
    "\n",
    "- A multi-layer perceptron with three hidden layers.\n",
    "- Uses **Batch Normalization** and **Dropout** to improve training stability and reduce overfitting.\n",
    "- Applies **GELU activation**, which often outperforms ReLU.\n",
    "- Weights are initialized using **Xavier uniform initialization**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0abd008f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úÖ Improved MLP with GELU and weight init\n",
    "class SuperMLP(nn.Module):\n",
    "    def __init__(self, input_dim, num_classes):\n",
    "        super(SuperMLP, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(64, num_classes)\n",
    "        )\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        for m in self.net:\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.zeros_(m.bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50fb32bc",
   "metadata": {},
   "source": [
    "## ‚úÖ Setup Device and Initialize Model\n",
    "\n",
    "- Automatically use **GPU** if available, otherwise default to **CPU**.\n",
    "- Instantiate the `SuperMLP` model with input dimension and number of output classes.\n",
    "- Move the model to the selected device.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fe364252",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úÖ Setup\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = SuperMLP(X_train.shape[1], len(np.unique(y))).to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e45e9200",
   "metadata": {},
   "source": [
    "## ‚öñÔ∏è Handle Class Imbalance with Class Weights and Setup Training Components\n",
    "\n",
    "- Compute **class weights** to address imbalanced classes during loss calculation.\n",
    "- Use **CrossEntropyLoss** with class weights.\n",
    "- Set up **AdamW optimizer** for training.\n",
    "- Use **Cosine Annealing LR scheduler** for learning rate adjustment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "da1f0966",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class weights to handle imbalance\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y_train), y=y_train)\n",
    "class_weights_tensor = torch.tensor(class_weights, dtype=torch.float32).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights_tensor)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.001)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da6f6ee",
   "metadata": {},
   "source": [
    "## üîÑ Training Loop with Early Stopping\n",
    "\n",
    "- Train the model for up to 130 epochs.\n",
    "- Track training loss and validation accuracy.\n",
    "- Use early stopping to stop training if validation accuracy doesn‚Äôt improve for 10 consecutive epochs.\n",
    "- Save the best model state during training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7988c5f1",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Numpy is not available",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 21\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m     20\u001b[0m     val_preds \u001b[38;5;241m=\u001b[39m model(X_test_tensor\u001b[38;5;241m.\u001b[39mto(device))\n\u001b[1;32m---> 21\u001b[0m     val_pred_labels \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39margmax(val_preds, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[0;32m     22\u001b[0m     val_acc \u001b[38;5;241m=\u001b[39m accuracy_score(y_test, val_pred_labels)\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrunning_loss\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mlen\u001b[39m(train_dl)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Val Acc: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_acc\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Numpy is not available"
     ]
    }
   ],
   "source": [
    "# ‚úÖ Training loop with early stopping\n",
    "best_acc = 0\n",
    "epochs_no_improve = 0\n",
    "for epoch in range(130):\n",
    "    model.train()\n",
    "    running_loss = 0\n",
    "    for xb, yb in train_dl:\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        preds = model(xb)\n",
    "        loss = criterion(preds, yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    scheduler.step()\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_preds = model(X_test_tensor.to(device))\n",
    "        val_pred_labels = torch.argmax(val_preds, dim=1).cpu().numpy()\n",
    "        val_acc = accuracy_score(y_test, val_pred_labels)\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}, Loss: {running_loss/len(train_dl):.4f}, Val Acc: {val_acc:.4f}\")\n",
    "    \n",
    "    # Early stopping\n",
    "    if val_acc > best_acc:\n",
    "        best_acc = val_acc\n",
    "        epochs_no_improve = 0\n",
    "        best_model = model.state_dict()\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "        if epochs_no_improve == 10:\n",
    "            print(f\"‚èπÔ∏è Early stopping at epoch {epoch+1}\")\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd2e3334",
   "metadata": {},
   "source": [
    "## üìä Final Evaluation\n",
    "\n",
    "- Load the best model saved during training.\n",
    "- Evaluate on the test set.\n",
    "- Calculate and print the **accuracy** and detailed **classification report**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5c31555f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Final MLP Accuracy: 0.824\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.98      0.95       402\n",
      "           1       0.83      0.80      0.82       406\n",
      "           2       0.72      0.54      0.62       408\n",
      "           3       0.83      0.91      0.87       401\n",
      "           4       0.78      0.91      0.84       383\n",
      "\n",
      "    accuracy                           0.82      2000\n",
      "   macro avg       0.82      0.83      0.82      2000\n",
      "weighted avg       0.82      0.82      0.82      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ‚úÖ Evaluation\n",
    "model.load_state_dict(best_model)\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    preds = model(X_test_tensor.to(device))\n",
    "    pred_labels = torch.argmax(preds, dim=1).cpu().numpy()\n",
    "\n",
    "acc = accuracy_score(y_test, pred_labels)\n",
    "print(\"\\nüìä Final MLP Accuracy:\", round(acc, 4))\n",
    "print(classification_report(y_test, pred_labels))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DM_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
